Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,-4.7782516,39.54435483870968,-1.5510054878094548,-1.5510054878094548,1.0
20000,1.4165193,-3.8547668,40.33195020746888,-1.5771704386365346,-1.5771704386365346,1.0
30000,1.4152198,-3.658999,39.403225806451616,-1.5649130023557518,-1.5649130023557518,1.0
40000,1.4139167,-3.293822,43.847533632286996,-1.6299036350180163,-1.6299036350180163,1.0
50000,1.4142108,-2.8741925,39.790983606557376,-1.6493811622515027,-1.6493811622515027,1.0
60000,1.4155548,-2.6307707,41.063025210084035,-1.6164465974666067,-1.6164465974666067,1.0
70000,1.4170538,-2.427757,43.517857142857146,-1.6093283706892463,-1.6093283706892463,1.0
80000,1.4189218,-2.3111615,46.91866028708134,-1.6416205929574637,-1.6416205929574637,1.0
