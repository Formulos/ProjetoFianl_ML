Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,36.73106060606061,13.466493,-1.111685602897496,-1.111685602897496,1.0
20000,1.4189384,35.50909090909091,13.390799,-1.133521896426695,-1.133521896426695,1.0
30000,1.4189383,34.60931899641577,13.015553,-1.1089999987078565,-1.1089999987078565,1.0
40000,1.4189383,33.25684931506849,14.378993,-1.1269006891405746,-1.1269006891405746,1.0
50000,1.4189383,35.921933085501855,13.335162,-1.1227407403566219,-1.1227407403566219,1.0
60000,1.4189383,35.6007326007326,13.480858,-1.1322161179759127,-1.1322161179759127,1.0
70000,1.4189384,35.91941391941392,13.721417,-1.1350735285702873,-1.1350735285702873,1.0
80000,1.4189383,35.13405797101449,14.062655,-1.1196942400160452,-1.1196942400160452,1.0
