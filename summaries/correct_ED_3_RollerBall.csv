Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
990000,1.3441533,136.9,1.0476794,3.556149871647358,3.556149871647358,1.0
1000000,1.3438593,177.45762711864407,0.68281513,2.436101641032403,2.436101641032403,1.0
1010000,1.3422619,180.88235294117646,0.6950569,2.4526922234978814,2.4526922234978814,1.0
1020000,1.3406457,190.68,0.70496064,2.3018099366500975,2.3018099366500975,1.0
1030000,1.3401227,187.70909090909092,0.74019,2.4746362717991524,2.4746362717991524,1.0
1040000,1.3396411,180.51785714285714,0.8326687,2.7972588359178707,2.7972588359178707,1.0
1050000,1.3393513,177.46428571428572,0.92854583,2.9298302502304847,2.9298302502304847,1.0
1060000,1.3395737,170.95,0.909549,3.0605591934931984,3.0605591934931984,1.0
1070000,1.339484,184.12727272727273,0.87204576,3.094360991450096,3.094360991450096,1.0
1080000,1.3392487,175.2037037037037,0.9519976,3.2862908352505076,3.2862908352505076,1.0
1090000,1.3381499,176.76363636363635,0.8870911,3.1491427318791727,3.1491427318791727,1.0
1100000,1.3374639,183.01785714285714,1.0707752,3.076508855879573,3.076508855879573,1.0
