Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,32.898648648648646,-2.5669298,-5.583382528616851,-5.583382528616851,1.0
20000,1.417724,33.49655172413793,-2.7519376,-5.572752237914731,-5.572752237914731,1.0
30000,1.4188877,34.95306859205776,-2.9812446,-5.442799528084853,-5.442799528084853,1.0
40000,1.4200511,39.6869918699187,-3.3037384,-5.547337772771989,-5.547337772771989,1.0
50000,1.4228369,46.649289099526065,-3.793009,-5.7919384672862035,-5.7919384672862035,1.0
60000,1.4236454,46.80288461538461,-3.9827757,-5.550708408191438,-5.550708408191438,1.0
70000,1.423368,51.05235602094241,-4.1306005,-5.771346830023011,-5.771346830023011,1.0
80000,1.424941,52.16489361702128,-4.353114,-5.660098926969848,-5.660098926969848,1.0
90000,1.4263734,81.9322033898305,-4.057378,-5.365228208208141,-5.365228208208141,1.0
100000,1.4269502,141.41666666666666,-2.969224,-5.4458604223032125,-5.4458604223032125,1.0
