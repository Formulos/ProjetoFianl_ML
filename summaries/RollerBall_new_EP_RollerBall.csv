Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,0.23495604,116.61176470588235,-3.220823334069813,-3.220823334069813,1.0
20000,1.4212892,0.48359385,152.55555555555554,-3.9671426101750327,-3.9671426101750327,1.0
30000,1.42136,0.43133777,178.63636363636363,-4.440726985037327,-4.440726985037327,1.0
40000,1.4209104,0.3658826,167.79032258064515,-4.3329505407724715,-4.3329505407724715,1.0
50000,1.4216999,0.32727394,155.9047619047619,-3.9878903756616637,-3.9878903756616637,1.0
60000,1.4238682,-0.25826448,241.825,-6.067749615455978,-6.067749615455978,1.0
70000,1.4263254,0.2012771,175.72413793103448,-4.531206617436918,-4.531206617436918,1.0
80000,1.4270422,0.07425472,152.28125,-3.8792966280452674,-3.8792966280452674,1.0
90000,1.4254156,-0.1004785,128.2125,-3.326328894559624,-3.326328894559624,1.0
100000,1.4238795,0.08566459,160.01612903225808,-4.136507686050165,-4.136507686050165,1.0
110000,1.4247501,-0.39161807,152.234375,-3.9100778722640825,-3.9100778722640825,1.0
120000,1.4269418,-0.59068453,113.69318181818181,-2.9732384444320235,-2.9732384444320235,1.0
130000,1.4266938,-0.654168,77.0859375,-2.1763670507716597,-2.1763670507716597,1.0
140000,1.4242038,-0.72338986,68.86713286713287,-2.0544753917655743,-2.0544753917655743,1.0
150000,1.4216825,-0.8914401,79.184,-2.2310798699334264,-2.2310798699334264,1.0
160000,1.4202225,-0.88900924,73.17164179104478,-2.1503332016437695,-2.1503332016437695,1.0
170000,1.4194852,-0.9641731,76.1,-2.2813075557422753,-2.2813075557422753,1.0
180000,1.4184022,-1.0377024,74.37878787878788,-2.158257444995935,-2.158257444995935,1.0
190000,1.4176238,-1.1719351,75.87786259541984,-2.2070767789792556,-2.2070767789792556,1.0
200000,1.416727,-1.1719191,88.74545454545455,-2.495765609859682,-2.495765609859682,1.0
