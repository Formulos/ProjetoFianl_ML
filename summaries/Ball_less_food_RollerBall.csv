Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
100000,1.4189383,30.876033057851238,3.1805992,-1.0965289253094965,-1.0965289253094965,1.0
110000,1.4189383,30.980891719745223,3.0341156,-1.0912101901830382,-1.0912101901830382,1.0
120000,1.4189383,30.765079365079366,1.9933589,-1.0978821629456654,-1.0978821629456654,1.0
130000,1.4189383,30.437106918238992,2.3242993,-1.0899842739480097,-1.0899842739480097,1.0
140000,1.4189383,31.125,2.6403167,-1.1018269241620333,-1.1018269241620333,1.0
150000,1.4189383,29.370030581039757,2.1108024,-1.1057902731703408,-1.1057902731703408,1.0
160000,1.4189383,30.018633540372672,1.7718886,-1.1131211163834756,-1.1131211163834756,1.0
170000,1.4189383,32.76949152542373,3.0375984,-1.1083108105671566,-1.1083108105671566,1.0
180000,1.4189383,29.557926829268293,2.974723,-1.1051067052999648,-1.1051067052999648,1.0
