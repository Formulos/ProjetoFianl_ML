Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
30000,1.4187473,56.26829268292683,4.660317,1.170731707317073,1.170731707317073,1.0
40000,1.4199438,61.742138364779876,4.618709,1.2232704402515724,1.2232704402515724,1.0
50000,1.4220524,57.19767441860465,4.634761,1.0872093023255813,1.0872093023255813,1.0
60000,1.4237522,85.49122807017544,4.771231,1.868421052631579,1.868421052631579,1.0
70000,1.4251559,157.82258064516128,4.664189,3.6451612903225805,3.6451612903225805,1.0
80000,1.425142,174.3793103448276,4.5815763,3.3706896551724137,3.3706896551724137,1.0
90000,1.4246976,191.7450980392157,4.778418,3.343137254901961,3.343137254901961,1.0
100000,1.4240178,407.12,4.74949,5.72,5.72,1.0
110000,1.4220932,631.0625,4.592641,6.875,6.875,1.0
120000,1.4204252,472.95,4.3796716,5.125,5.125,1.0
130000,1.4210038,895.4545454545455,4.1601305,6.545454545454546,6.545454545454546,1.0
140000,1.4209254,1050.7142857142858,3.7153049,6.142857142857143,6.142857142857143,1.0
150000,1.4213929,None,3.1266658,None,None,1.0
160000,1.4215854,17382.0,2.9437532,20.5,20.5,1.0
170000,1.4190663,1654.2222222222222,2.7530549,7.833333333333333,7.833333333333333,1.0
180000,1.4183761,None,2.49214,None,None,1.0
