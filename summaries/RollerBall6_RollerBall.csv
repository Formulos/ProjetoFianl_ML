Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
210000,1.417904,0.8405292,66.0,-1.0660999938845634,-1.0660999938845634,1.0
220000,1.4174974,0.706304,None,None,None,1.0
230000,1.4173211,0.64793456,5332.5,-5.258000330401046,-5.258000330401046,1.0
240000,1.4181362,0.6535191,None,None,None,1.0
250000,1.4182736,0.68348384,3021.285714285714,-3.2074859392388526,-3.2074859392388526,1.0
260000,1.4181381,0.610769,1316.2,-1.2865701380040264,-1.2865701380040264,1.0
270000,1.417817,0.4534485,1682.6666666666667,-1.466300195119402,-1.466300195119402,1.0
280000,1.4159651,0.4231281,1936.0,-1.3029337376356125,-1.3029337376356125,1.0
290000,1.4136398,0.32638508,1755.0,-1.38045024693929,-1.38045024693929,1.0
300000,1.411692,0.3193927,4786.5,-4.28695039259037,-4.28695039259037,1.0
310000,1.4099917,0.24961975,None,None,None,1.0
320000,1.4074519,0.2001466,None,None,None,1.0
330000,1.4051545,0.20669465,5774.2,-5.6346403904201,-5.6346403904201,1.0
340000,1.4043279,0.11885961,None,None,None,1.0
350000,1.4022617,0.0950602,None,None,None,1.0
360000,1.4005687,0.08074415,None,None,None,1.0
370000,1.3988816,0.066192895,None,None,None,1.0
380000,1.3951296,0.068602525,None,None,None,1.0
390000,1.3890753,0.050688244,None,None,None,1.0
