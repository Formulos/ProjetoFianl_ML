Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
50000,1.4324933,66.5691056910569,-0.25720343,-0.09430892583800525,-0.09430892583800525,1.0
60000,1.4344494,72.94814814814815,-7.0661206,0.0414815037338822,0.0414815037338822,1.0
70000,1.4362922,67.61904761904762,1.0535736,0.04761906627084122,0.04761906627084122,1.0
80000,1.4377588,73.55639097744361,-0.79239845,-0.02857140849407454,-0.02857140849407454,1.0
90000,1.4395757,67.37837837837837,-2.5483434,-0.09594592854783342,-0.09594592854783342,1.0
100000,1.4416368,63.1025641025641,-3.1854663,-0.04999998135444445,-0.04999998135444445,1.0
110000,1.4457244,70.72661870503597,-1.0734686,-0.07913667263744546,-0.07913667263744546,1.0
120000,1.4486722,64.3202614379085,-2.4595966,-0.049673183291566135,-0.049673183291566135,1.0
130000,1.4510806,64.49668874172185,-3.9371378,-0.08874170353870518,-0.08874170353870518,1.0
140000,1.4534497,70.37062937062937,0.40458643,-0.10563378602686063,-0.10563378602686063,1.0
150000,1.4555606,63.69736842105263,-0.09649938,-0.07712416477452695,-0.07712416477452695,1.0
160000,1.457861,64.70779220779221,-1.3189832,-0.005228736821342917,-0.005228736821342917,1.0
170000,1.4594443,65.88590604026845,-3.0393944,-0.04105958401762097,-0.04105958401762097,1.0
180000,1.4607531,62.83225806451613,-0.35026,-0.09032256295604091,-0.09032256295604091,1.0
190000,1.4619759,62.58490566037736,-1.2403617,-0.1295597328329986,-0.1295597328329986,1.0
200000,1.4624342,57.47953216374269,-1.2792726,-0.06432746795185826,-0.06432746795185826,1.0
210000,1.4632767,59.31333333333333,-0.67113525,2.0861625671386717e-08,2.0861625671386717e-08,1.0
220000,1.4643642,71.25179856115108,-0.2978928,-0.027338108570455648,-0.027338108570455648,1.0
