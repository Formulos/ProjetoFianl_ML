Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
280000,1.4480469,1.073037,866.0,2.5,2.5,1.0
290000,1.4479488,0.53170294,1145.25,2.5,2.5,1.0
300000,1.4474326,0.8792961,837.6923076923077,2.3846153846153846,2.3846153846153846,1.0
310000,1.4466217,0.06592839,712.7,1.05,1.05,1.0
320000,1.444716,0.1747696,1249.0,2.9166666666666665,2.9166666666666665,1.0
330000,1.4441037,0.34116313,1591.875,3.875,3.875,1.0
340000,1.4442946,0.36283746,1503.625,2.6875,2.6875,1.0
350000,1.4449438,0.56559527,605.75,2.375,2.375,1.0
