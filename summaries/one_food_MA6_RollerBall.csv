Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
140000,1.4020575,566.5,-0.19652852,-0.35714285714285715,-0.35714285714285715,1.0
150000,1.4006009,None,-0.13033254,None,None,1.0
160000,1.3987402,7221.333333333333,-0.12829879,1.6666666666666667,1.6666666666666667,1.0
170000,1.3968399,1059.2222222222222,-0.012996489,0.1111111111111111,0.1111111111111111,1.0
180000,1.3953475,3166.0,-0.032488253,1.0,1.0,1.0
190000,1.3929821,None,0.036115985,None,None,1.0
200000,1.3890849,None,0.057958383,None,None,1.0
210000,1.386392,None,0.07704883,None,None,1.0
220000,1.382604,39672.0,-0.06337766,1.0,1.0,1.0
230000,1.3796889,None,-0.09329875,None,None,1.0
